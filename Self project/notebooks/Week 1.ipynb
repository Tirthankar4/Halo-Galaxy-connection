{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "035f64f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smogn\n",
    "import h5py\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import pearsonr, ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "833a891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3.*10**8\n",
    "\n",
    "with h5py.File('data/fof_subhalo_tab_033.hdf5', 'r') as f:\n",
    "    # Positions, velocities and masses of the halos\n",
    "    M_h =   f['Group/Group_M_Crit200'][:]*1e10      #Msun/h\n",
    "    R_h =   f['Group/Group_R_Crit200'][:]/c         #kpc/h\n",
    "    V_h  =  f['Group/GroupVel'][:]                  #km/s\n",
    "    V_h =   np.linalg.norm(V_h, axis = 1)\n",
    "    ID_r =  f['Group/GroupFirstSub'][:] #Contains halos without gals as this number = -1\n",
    "    ID_h =  np.arange(0, M_h.shape[0], 1, dtype = float) #It is the ID of the halos, to match the gal cat\n",
    "\n",
    "    # Positions, stellar masses,  of the galaxies\n",
    "    SM     = f['Subhalo/SubhaloMassType'][:, 4]*1e10 #Msun/h\n",
    "    SFR    = f['Subhalo/SubhaloSFR'][:]*1e10 #Msun/yr\n",
    "    SR = f['Subhalo/SubhaloHalfmassRadType'][:, 4]\n",
    "    Colour = f['Subhalo/SubhaloStellarPhotometrics'][:, 5] - f['Subhalo/SubhaloStellarPhotometrics'][:, 6] #g-i \n",
    "    ID_g = np.array(f['Subhalo/SubhaloGrNr']) #Gals IDs\n",
    "\n",
    "indexes = np.where( ID_r != -1)[0]\n",
    "M_h = M_h[indexes]\n",
    "R_h = R_h[indexes]\n",
    "V_h = V_h[indexes]\n",
    "ID_h = ID_h[indexes]\n",
    "\n",
    "# Halo catalog\n",
    "data = np.array( [ M_h, R_h, V_h, ID_h ] ).T\n",
    "columns = [ 'M_h', 'R_h', 'V_h', 'ID' ] \n",
    "halos = pd.DataFrame(data = data, columns = columns)\n",
    "\n",
    "indexes = np.where(SM > 0)[0]\n",
    "SM = SM[indexes]\n",
    "SFR = SFR[indexes]\n",
    "SR = SR[indexes]\n",
    "Colour = Colour[indexes]\n",
    "ID_g = ID_g[indexes]\n",
    "\n",
    "#Galaxy catalog\n",
    "data = np.array([SM, SFR, Colour, SR, ID_g]).T\n",
    "columns = ['SM', 'SFR', 'Colour', 'SR', 'ID']\n",
    "gals = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "gals = gals.drop_duplicates(subset = ['ID'], keep = 'first')\n",
    "\n",
    "gals['SFR'] = gals['SFR'].replace(0, 1)\n",
    "gals['SFR'] = np.log10(gals['SFR'])\n",
    "gals.loc[gals['SFR'] == 0, 'SFR'] = np.random.normal(8.0, 0.5, len(gals.loc[gals['SFR'] == 0]))\n",
    "#gals.shape\n",
    "\n",
    "#SM.shape, M_h.shape\n",
    "\n",
    "df = pd.merge(left = halos, right = gals, left_on = 'ID', right_on = 'ID')\n",
    "\n",
    "df['M_h'] = np.log10(df['M_h'] + 0.01)\n",
    "df['R_h'] = np.log10(df['R_h'] + 0.01)\n",
    "df['V_h'] = np.log10(df['V_h'] + 0.01)\n",
    "\n",
    "df['SM']  = np.log10(df['SM'] + 0.01)\n",
    "#df['SR']  = np.log10(df['SR'] + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14cd3cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_h</th>\n",
       "      <th>R_h</th>\n",
       "      <th>V_h</th>\n",
       "      <th>ID</th>\n",
       "      <th>SM</th>\n",
       "      <th>SFR</th>\n",
       "      <th>Colour</th>\n",
       "      <th>SR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.708978</td>\n",
       "      <td>-1.999990</td>\n",
       "      <td>2.141859</td>\n",
       "      <td>1105.073587</td>\n",
       "      <td>7.862840</td>\n",
       "      <td>8.308993</td>\n",
       "      <td>0.216815</td>\n",
       "      <td>3.470842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.577714</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.242958</td>\n",
       "      <td>1305.457871</td>\n",
       "      <td>0.992273</td>\n",
       "      <td>0.700563</td>\n",
       "      <td>0.058822</td>\n",
       "      <td>3.823537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.159530</td>\n",
       "      <td>-1.999997</td>\n",
       "      <td>0.852127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.240346</td>\n",
       "      <td>6.573544</td>\n",
       "      <td>-0.308596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.342783</td>\n",
       "      <td>-1.999993</td>\n",
       "      <td>2.001723</td>\n",
       "      <td>380.250000</td>\n",
       "      <td>7.110663</td>\n",
       "      <td>7.848868</td>\n",
       "      <td>0.204559</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.605010</td>\n",
       "      <td>-1.999992</td>\n",
       "      <td>2.158675</td>\n",
       "      <td>785.500000</td>\n",
       "      <td>7.534524</td>\n",
       "      <td>8.218400</td>\n",
       "      <td>0.223761</td>\n",
       "      <td>3.179318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.983194</td>\n",
       "      <td>-1.999989</td>\n",
       "      <td>2.310053</td>\n",
       "      <td>1370.750000</td>\n",
       "      <td>8.308563</td>\n",
       "      <td>8.671782</td>\n",
       "      <td>0.238508</td>\n",
       "      <td>5.235649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.653268</td>\n",
       "      <td>-1.999916</td>\n",
       "      <td>2.750756</td>\n",
       "      <td>17953.000000</td>\n",
       "      <td>11.630214</td>\n",
       "      <td>10.718828</td>\n",
       "      <td>0.389301</td>\n",
       "      <td>32.569843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               M_h          R_h          V_h            ID           SM  \\\n",
       "count  1522.000000  1522.000000  1522.000000   1522.000000  1522.000000   \n",
       "mean     10.708978    -1.999990     2.141859   1105.073587     7.862840   \n",
       "std       0.577714     0.000006     0.242958   1305.457871     0.992273   \n",
       "min       9.159530    -1.999997     0.852127      0.000000     6.240346   \n",
       "25%      10.342783    -1.999993     2.001723    380.250000     7.110663   \n",
       "50%      10.605010    -1.999992     2.158675    785.500000     7.534524   \n",
       "75%      10.983194    -1.999989     2.310053   1370.750000     8.308563   \n",
       "max      13.653268    -1.999916     2.750756  17953.000000    11.630214   \n",
       "\n",
       "               SFR       Colour           SR  \n",
       "count  1522.000000  1522.000000  1522.000000  \n",
       "mean      8.308993     0.216815     3.470842  \n",
       "std       0.700563     0.058822     3.823537  \n",
       "min       6.573544    -0.308596     0.000000  \n",
       "25%       7.848868     0.204559     0.000000  \n",
       "50%       8.218400     0.223761     3.179318  \n",
       "75%       8.671782     0.238508     5.235649  \n",
       "max      10.718828     0.389301    32.569843  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e43f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1522 entries, 0 to 1521\n",
      "Data columns (total 8 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   M_h     1522 non-null   float64\n",
      " 1   R_h     1522 non-null   float64\n",
      " 2   V_h     1522 non-null   float64\n",
      " 3   ID      1522 non-null   float64\n",
      " 4   SM      1522 non-null   float64\n",
      " 5   SFR     1522 non-null   float64\n",
      " 6   Colour  1522 non-null   float64\n",
      " 7   SR      1522 non-null   float64\n",
      "dtypes: float64(8)\n",
      "memory usage: 95.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (12, 3), sharey = True, dpi = 100)\n",
    "\n",
    "fig.suptitle('Halo properties')\n",
    "\n",
    "axs[0].hist(df['M_h'])\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('M_h')\n",
    "axs[0].set_ylabel('# halos')\n",
    "\n",
    "axs[1].hist(df['R_h'])\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('R_h')\n",
    "\n",
    "axs[2].hist(df['V_h'])\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlabel('V_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819c3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 4, figsize = (16, 3), sharey = True, dpi = 100)\n",
    "\n",
    "fig.suptitle('Galaxy properties')\n",
    "\n",
    "axs[0].hist(df['SM'], bins = 40)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel(r'$M_{\\star}$')\n",
    "axs[0].set_ylabel('# halos')\n",
    "\n",
    "axs[1].hist(df['Colour'], bins = 40)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('Color')\n",
    "\n",
    "axs[2].hist(df['SFR'], bins = 40)\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlabel('SFR')\n",
    "\n",
    "axs[3].hist(df['SR'], bins = 40)\n",
    "axs[3].set_yscale('log')\n",
    "axs[3].set_xlabel('SR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7234b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    correlations = df.corr(method = 'pearson')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8,8))\n",
    "    sns.heatmap(correlations, vmax = 1.0, center = 0, fmt = '.4f',\n",
    "                square = True, linewidths = .5, annot = True, \n",
    "                cbar_kws = {\"shrink\": .82})\n",
    "    plt.title('Pearson correlation Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c388775",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size=1):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc4 = nn.Linear(hidden_size, hidden_size)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.relu(self.fc4(x))\n",
    "\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5449a867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED TRAINING FUNCTIONS WITH LOSS TRACKING\n",
    "\n",
    "def train_neural_network(X_train, X_test, y_train, y_test, num_epochs=500):\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    if y_train.ndim == 1:\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "    if y_test.ndim == 1:\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    mean_data = np.mean(X_train, axis=0)\n",
    "    std_data = np.std(X_train, axis=0)\n",
    "    \n",
    "    X_train_norm = (X_train - mean_data) / std_data\n",
    "    X_test_norm = (X_test - mean_data) / std_data\n",
    "\n",
    "    mean_targets = np.mean(y_train, axis=0)\n",
    "    std_targets = np.std(y_train, axis=0)\n",
    "    \n",
    "    y_train_norm = (y_train - mean_targets) / std_targets\n",
    "    y_test_norm = (y_test - mean_targets) / std_targets\n",
    "\n",
    "    X_train_tensor = torch.FloatTensor(X_train_norm.values if hasattr(X_train_norm, 'values') else X_train_norm)\n",
    "    y_train_tensor = torch.FloatTensor(y_train_norm)\n",
    "    X_test_tensor = torch.FloatTensor(X_test_norm.values if hasattr(X_test_norm, 'values') else X_test_norm)\n",
    "    y_test_tensor = torch.FloatTensor(y_test_norm)\n",
    "\n",
    "    input_size = X_train_tensor.shape[1]\n",
    "    model = SimpleMLP(input_size, hidden_size=128)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Track losses\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # Evaluate on test set\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = model(X_test_tensor)\n",
    "            test_loss = criterion(test_outputs, y_test_tensor)\n",
    "            test_losses.append(test_loss.item())\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_norm = model(X_test_tensor).numpy()\n",
    "\n",
    "    y_pred = y_pred_norm * std_targets + mean_targets\n",
    "    \n",
    "    metrics = {}\n",
    "    for i in range(y_test.shape[1]):\n",
    "        mse = mean_squared_error(y_test[:, i], y_pred[:, i])\n",
    "        pearson_corr, pearson_pval = pearsonr(y_test[:, i], y_pred[:, i])\n",
    "        ks_stat, ks_pval = ks_2samp(y_test[:, i], y_pred[:, i])\n",
    "        \n",
    "        metrics[f'target_{i}'] = {\n",
    "            'MSE': mse,\n",
    "            'Pearson_r': pearson_corr,\n",
    "            'Pearson_pval': pearson_pval,\n",
    "            'KS_statistic': ks_stat,\n",
    "            'KS_pval': ks_pval\n",
    "        }\n",
    "    \n",
    "    return y_pred, metrics, train_losses, test_losses\n",
    "\n",
    "\n",
    "def train_extra_trees(X_train, X_test, y_train, y_test, num_estimators_list=None):\n",
    "    \"\"\"\n",
    "    ExtraTreesRegressor doesn't have traditional epochs, so we track performance\n",
    "    as trees are added to the ensemble\n",
    "    \"\"\"\n",
    "    if num_estimators_list is None:\n",
    "        num_estimators_list = [10, 20, 50, 100, 150, 200]\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    if y_train.ndim == 1:\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "    if y_test.ndim == 1:\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Train with increasing number of estimators\n",
    "    for n_est in num_estimators_list:\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=n_est,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        if y_train.shape[1] == 1:\n",
    "            y_train_flat = y_train.ravel()\n",
    "        else:\n",
    "            y_train_flat = y_train\n",
    "        \n",
    "        model.fit(X_train, y_train_flat)\n",
    "        \n",
    "        # Training loss\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        if y_train_pred.ndim == 1:\n",
    "            y_train_pred = y_train_pred.reshape(-1, 1)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        train_losses.append(train_mse)\n",
    "        \n",
    "        # Test loss\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        if y_test_pred.ndim == 1:\n",
    "            y_test_pred = y_test_pred.reshape(-1, 1)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        test_losses.append(test_mse)\n",
    "    \n",
    "    # Final model with 200 estimators\n",
    "    model = ExtraTreesRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    if y_train.shape[1] == 1:\n",
    "        y_train = y_train.ravel()\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = np.array(y_pred)\n",
    "    if y_pred.ndim == 1:\n",
    "        y_pred = y_pred.reshape(-1, 1)\n",
    "    \n",
    "    metrics = {}\n",
    "    for i in range(y_test.shape[1]):\n",
    "        mse = mean_squared_error(y_test[:, i], y_pred[:, i])\n",
    "        pearson_corr, pearson_pval = pearsonr(y_test[:, i], y_pred[:, i])\n",
    "        ks_stat, ks_pval = ks_2samp(y_test[:, i], y_pred[:, i])\n",
    "        \n",
    "        metrics[f'target_{i}'] = {\n",
    "            'MSE': mse,\n",
    "            'Pearson_r': pearson_corr,\n",
    "            'Pearson_pval': pearson_pval,\n",
    "            'KS_statistic': ks_stat,\n",
    "            'KS_pval': ks_pval\n",
    "        }\n",
    "\n",
    "    return y_pred, metrics, train_losses, test_losses, num_estimators_list\n",
    "\n",
    "\n",
    "def train_knn(X_train, X_test, y_train, y_test, k_values=None):\n",
    "    \"\"\"\n",
    "    KNN doesn't have training in traditional sense, so we track performance\n",
    "    across different k values\n",
    "    \"\"\"\n",
    "    if k_values is None:\n",
    "        k_values = [3, 5, 7, 10, 15, 20, 30]\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    if y_train.ndim == 1:\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "    if y_test.ndim == 1:\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_X.transform(X_test)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    # Try different k values\n",
    "    for k in k_values:\n",
    "        model = KNeighborsRegressor(\n",
    "            n_neighbors=k,\n",
    "            weights='distance',\n",
    "            algorithm='auto',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        if y_train_scaled.shape[1] == 1:\n",
    "            y_train_scaled_flat = y_train_scaled.ravel()\n",
    "        else:\n",
    "            y_train_scaled_flat = y_train_scaled\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train_scaled_flat)\n",
    "        \n",
    "        # Training loss\n",
    "        y_train_pred_scaled = model.predict(X_train_scaled)\n",
    "        if y_train_pred_scaled.ndim == 1:\n",
    "            y_train_pred_scaled = y_train_pred_scaled.reshape(-1, 1)\n",
    "        y_train_pred = scaler_y.inverse_transform(y_train_pred_scaled)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        train_losses.append(train_mse)\n",
    "        \n",
    "        # Test loss\n",
    "        y_test_pred_scaled = model.predict(X_test_scaled)\n",
    "        if y_test_pred_scaled.ndim == 1:\n",
    "            y_test_pred_scaled = y_test_pred_scaled.reshape(-1, 1)\n",
    "        y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        test_losses.append(test_mse)\n",
    "    \n",
    "    # Final model with k=10\n",
    "    model = KNeighborsRegressor(\n",
    "        n_neighbors=10,\n",
    "        weights='distance',\n",
    "        algorithm='auto',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Fit with flattened y if needed\n",
    "    if y_train_scaled.shape[1] == 1:\n",
    "        y_train_scaled_flat = y_train_scaled.ravel()\n",
    "    else:\n",
    "        y_train_scaled_flat = y_train_scaled\n",
    "    \n",
    "    model.fit(X_train_scaled, y_train_scaled_flat)\n",
    "    y_pred_scaled = model.predict(X_test_scaled)\n",
    "    \n",
    "    # FIX: Ensure y_pred_scaled is 2D before inverse_transform\n",
    "    if y_pred_scaled.ndim == 1:\n",
    "        y_pred_scaled = y_pred_scaled.reshape(-1, 1)\n",
    "    \n",
    "    y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "    \n",
    "    metrics = {}\n",
    "    for i in range(y_test.shape[1]):\n",
    "        mse = mean_squared_error(y_test[:, i], y_pred[:, i])\n",
    "        pearson_corr, pearson_pval = pearsonr(y_test[:, i], y_pred[:, i])\n",
    "        ks_stat, ks_pval = ks_2samp(y_test[:, i], y_pred[:, i])\n",
    "        \n",
    "        metrics[f'target_{i}'] = {\n",
    "            'MSE': mse,\n",
    "            'Pearson_r': pearson_corr,\n",
    "            'Pearson_pval': pearson_pval,\n",
    "            'KS_statistic': ks_stat,\n",
    "            'KS_pval': ks_pval\n",
    "        }\n",
    "\n",
    "    return y_pred, metrics, train_losses, test_losses, k_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1a075e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SM1 = df['SM'].values\n",
    "SFR1 = df['SFR'].values\n",
    "Colour1 = df['Colour'].values\n",
    "SR1 = df['SR'].values\n",
    "\n",
    "df1 = df.copy()\n",
    "df1.drop(['SFR', 'Colour', 'SR'], axis=1, inplace=True)\n",
    "\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(df1, SM1, test_size=0.2, random_state=42)\n",
    "X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr = train_test_split(df1, SFR1, test_size=0.2, random_state=42)\n",
    "X_train_colour, X_test_colour, y_train_colour, y_test_colour = train_test_split(df1, Colour1, test_size=0.2, random_state=42)\n",
    "X_train_sr, X_test_sr, y_train_sr, y_test_sr = train_test_split(df1, SR1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb75776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tirth\\AppData\\Roaming\\Python\\Python313\\site-packages\\scipy\\stats\\_axis_nan_policy.py:586: RuntimeWarning: ks_2samp: Exact calculation unsuccessful. Switching to method=asymp.\n",
      "  res = hypotest_fun_out(*samples, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "y_raw_nn_sm, metrics_raw_nn_sm, train_loss_raw_nn_sm, test_loss_raw_nn_sm = train_neural_network(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_raw_nn_sfr, metrics_raw_nn_sfr, train_loss_raw_nn_sfr, test_loss_raw_nn_sfr = train_neural_network(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_raw_nn_colour, metrics_raw_nn_colour, train_loss_raw_nn_colour, test_loss_raw_nn_colour = train_neural_network(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_raw_nn_sr, metrics_raw_nn_sr, train_loss_raw_nn_sr, test_loss_raw_nn_sr = train_neural_network(X_train_sr, X_test_sr, y_train_sr, y_test_sr)\n",
    "\n",
    "# Extra Trees\n",
    "y_raw_et_sm, metrics_raw_et_sm, train_loss_raw_et_sm, test_loss_raw_et_sm, n_est_raw_sm = train_extra_trees(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_raw_et_sfr, metrics_raw_et_sfr, train_loss_raw_et_sfr, test_loss_raw_et_sfr, n_est_raw_sfr = train_extra_trees(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_raw_et_colour, metrics_raw_et_colour, train_loss_raw_et_colour, test_loss_raw_et_colour, n_est_raw_colour = train_extra_trees(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_raw_et_sr, metrics_raw_et_sr, train_loss_raw_et_sr, test_loss_raw_et_sr, n_est_raw_sr = train_extra_trees(X_train_sr, X_test_sr, y_train_sr, y_test_sr)\n",
    "\n",
    "# KNN\n",
    "y_raw_knn_sm, metrics_raw_knn_sm, train_loss_raw_knn_sm, test_loss_raw_knn_sm, k_vals_raw_sm = train_knn(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_raw_knn_sfr, metrics_raw_knn_sfr, train_loss_raw_knn_sfr, test_loss_raw_knn_sfr, k_vals_raw_sfr = train_knn(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_raw_knn_colour, metrics_raw_knn_colour, train_loss_raw_knn_colour, test_loss_raw_knn_colour, k_vals_raw_colour = train_knn(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_raw_knn_sr, metrics_raw_knn_sr, train_loss_raw_knn_sr, test_loss_raw_knn_sr, k_vals_raw_sr = train_knn(X_train_sr, X_test_sr, y_train_sr, y_test_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b08d52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dist_matrix: 100%|##########| 2/2 [00:00<00:00, 2744.07it/s]\n",
      "synth_matrix: 100%|##########| 2/2 [00:00<00:00,  2.07it/s]\n",
      "r_index: 100%|##########| 1/1 [00:00<00:00, 594.77it/s]\n",
      "dist_matrix: 100%|##########| 8/8 [00:00<00:00, 1005.86it/s]\n",
      "synth_matrix: 100%|##########| 8/8 [00:00<00:00, 40.88it/s]\n",
      "r_index: 100%|##########| 3/3 [00:00<00:00, 1122.77it/s]\n",
      "dist_matrix: 100%|##########| 33/33 [00:00<00:00, 384.16it/s]\n",
      "synth_matrix: 100%|##########| 33/33 [00:00<00:00, 36.11it/s]\n",
      "r_index: 100%|##########| 26/26 [00:00<00:00, 1202.64it/s]\n",
      "dist_matrix: 100%|##########| 457/457 [00:15<00:00, 28.64it/s]\n",
      "r_index: 100%|##########| 319/319 [00:00<00:00, 1135.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1522\n",
      "SM training set size after SMOGN: 2423 (+1206)\n",
      "SFR training set size after SMOGN: 1217 (+0)\n",
      "Colour training set size after SMOGN: 2365 (+1148)\n",
      "SR training set size after SMOGN: 1080 (+-137)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_smogn = df.copy()\n",
    "\n",
    "X = df_smogn.drop(['SM', 'SFR', 'Colour', 'SR'], axis=1)\n",
    "y_sm = df_smogn[['SM']]\n",
    "y_sfr = df_smogn[['SFR']]\n",
    "y_colour = df_smogn[['Colour']]\n",
    "y_sr = df_smogn[['SR']]\n",
    "\n",
    "X_train_sm, X_test_sm, y_train_sm, y_test_sm = train_test_split(X, y_sm, test_size=0.2, random_state=42)\n",
    "X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr = train_test_split(X, y_sfr, test_size=0.2, random_state=42)\n",
    "X_train_colour, X_test_colour, y_train_colour, y_test_colour = train_test_split(X, y_colour, test_size=0.2, random_state=42)\n",
    "X_train_sr, X_test_sr, y_train_sr, y_test_sr = train_test_split(X, y_sr, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train_sm = X_train_sm.copy()\n",
    "df_train_sm['SM'] = y_train_sm.values\n",
    "df_train_sm = df_train_sm.reset_index(drop=True)\n",
    "\n",
    "df_train_sfr = X_train_sfr.copy()\n",
    "df_train_sfr['SFR'] = y_train_sfr.values\n",
    "df_train_sfr = df_train_sfr.reset_index(drop=True)\n",
    "\n",
    "df_train_colour = X_train_colour.copy()\n",
    "df_train_colour['Colour'] = y_train_colour.values\n",
    "df_train_colour = df_train_colour.reset_index(drop=True)\n",
    "\n",
    "df_train_sr = X_train_sr.copy()\n",
    "df_train_sr['SR'] = y_train_sr.values\n",
    "df_train_sr = df_train_sr.reset_index(drop=True)\n",
    "\n",
    "df_train_sm = smogn.smoter(\n",
    "    data=df_train_sm,\n",
    "    y='SM',\n",
    "    k=3,                     # Further reduced from 5\n",
    "    pert=0.01,              # Much more conservative\n",
    "    samp_method='extreme',\n",
    "    rel_method='manual',\n",
    "    rel_ctrl_pts_rg=[\n",
    "        [6.5, 0, 0],        # Low mass: zero\n",
    "        [10.8, 0, 0],       # Mid-high mass: STILL zero\n",
    "        [11.2, 0.8, 0],     # Sharp transition\n",
    "        [11.4, 1, 0],       # Only the very highest\n",
    "        [11.63, 1, 0]\n",
    "    ],\n",
    "    under_samp=True         # Critical for reducing common regions\n",
    ")\n",
    "\n",
    "# SFR: Dual focus on extreme low AND extreme high\n",
    "df_train_sfr = smogn.smoter(\n",
    "    data=df_train_sfr,\n",
    "    y='SFR',\n",
    "    k=5,\n",
    "    pert=0.025,              # Reduced perturbation\n",
    "    samp_method='extreme',\n",
    "    rel_method='manual',\n",
    "    rel_ctrl_pts_rg=[\n",
    "        [-2.5, 1, 0],\n",
    "        [-0.5, 1, 0],\n",
    "        [2.0, 0, 0],         # Mid range: zero relevance\n",
    "        [8.5, 0.8, 0],       # High SFR increase\n",
    "        [9.2, 1, 0],         # Maximum for extreme high\n",
    "        [9.57, 1, 0]\n",
    "    ],\n",
    "    under_samp=True\n",
    ")\n",
    "\n",
    "# Colour: Extreme tails only\n",
    "df_train_colour = smogn.smoter(\n",
    "    data=df_train_colour,\n",
    "    y='Colour',\n",
    "    k=5,\n",
    "    pert=0.025,\n",
    "    samp_method='extreme',\n",
    "    rel_method='manual',\n",
    "    rel_ctrl_pts_rg=[\n",
    "        [-0.13, 0.9, 0],\n",
    "        [0.3, 0, 0],         # Central zero\n",
    "        [1.05, 0.7, 0],\n",
    "        [1.25, 1, 0],\n",
    "        [1.32, 1, 0]\n",
    "    ],\n",
    "    under_samp=True\n",
    ")\n",
    "\n",
    "# SR: High values\n",
    "df_train_sr = smogn.smoter(\n",
    "    data=df_train_sr,\n",
    "    y='SR',\n",
    "    k=5,\n",
    "    pert=0.025,\n",
    "    samp_method='extreme',\n",
    "    rel_method='manual',\n",
    "    rel_ctrl_pts_rg=[\n",
    "        [-2.0, 0, 0],\n",
    "        [0.5, 0, 0],\n",
    "        [1.0, 0.6, 0],\n",
    "        [1.3, 0.9, 0],\n",
    "        [1.48, 1, 0]\n",
    "    ],\n",
    "    under_samp=True\n",
    ")\n",
    "\n",
    "print(f\"Original dataset size: {len(df_smogn)}\")\n",
    "print(f\"SM training set size after SMOGN: {len(df_train_sm)} (+{len(df_train_sm) - len(X_train_sm)})\")\n",
    "print(f\"SFR training set size after SMOGN: {len(df_train_sfr)} (+{len(df_train_sfr) - len(X_train_sfr)})\")\n",
    "print(f\"Colour training set size after SMOGN: {len(df_train_colour)} (+{len(df_train_colour) - len(X_train_colour)})\")\n",
    "print(f\"SR training set size after SMOGN: {len(df_train_sr)} (+{len(df_train_sr) - len(X_train_sr)})\")\n",
    "\n",
    "X_train_sm = df_train_sm.drop(['SM'], axis=1)\n",
    "y_train_sm = df_train_sm[['SM']].values\n",
    "\n",
    "X_train_sfr = df_train_sfr.drop(['SFR'], axis=1)\n",
    "y_train_sfr = df_train_sfr[['SFR']].values\n",
    "\n",
    "X_train_colour = df_train_colour.drop(['Colour'], axis=1)\n",
    "y_train_colour = df_train_colour[['Colour']].values\n",
    "\n",
    "X_train_sr = df_train_sr.drop(['SR'], axis=1)\n",
    "y_train_sr = df_train_sr[['SR']].values\n",
    "\n",
    "X_test_sm = X_test_sm\n",
    "y_test_sm = y_test_sm.values\n",
    "\n",
    "X_test_sfr = X_test_sfr\n",
    "y_test_sfr = y_test_sfr.values\n",
    "\n",
    "X_test_colour = X_test_colour\n",
    "y_test_colour = y_test_colour.values\n",
    "\n",
    "X_test_sr = X_test_sr\n",
    "y_test_sr = y_test_sr.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f1a99dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "y_smogn_nn_sm, metrics_smogn_nn_sm, train_loss_smogn_nn_sm, test_loss_smogn_nn_sm = train_neural_network(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_smogn_nn_sfr, metrics_smogn_nn_sfr, train_loss_smogn_nn_sfr, test_loss_smogn_nn_sfr = train_neural_network(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_smogn_nn_colour, metrics_smogn_nn_colour, train_loss_smogn_nn_colour, test_loss_smogn_nn_colour = train_neural_network(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_smogn_nn_sr, metrics_smogn_nn_sr, train_loss_smogn_nn_sr, test_loss_smogn_nn_sr = train_neural_network(X_train_sr, X_test_sr, y_train_sr, y_test_sr)\n",
    "\n",
    "# Extra Trees\n",
    "y_smogn_et_sm, metrics_smogn_et_sm, train_loss_smogn_et_sm, test_loss_smogn_et_sm, n_est_smogn_sm = train_extra_trees(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_smogn_et_sfr, metrics_smogn_et_sfr, train_loss_smogn_et_sfr, test_loss_smogn_et_sfr, n_est_smogn_sfr = train_extra_trees(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_smogn_et_colour, metrics_smogn_et_colour, train_loss_smogn_et_colour, test_loss_smogn_et_colour, n_est_smogn_colour = train_extra_trees(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_smogn_et_sr, metrics_smogn_et_sr, train_loss_smogn_et_sr, test_loss_smogn_et_sr, n_est_smogn_sr = train_extra_trees(X_train_sr, X_test_sr, y_train_sr, y_test_sr)\n",
    "\n",
    "# KNN\n",
    "y_smogn_knn_sm, metrics_smogn_knn_sm, train_loss_smogn_knn_sm, test_loss_smogn_knn_sm, k_vals_smogn_sm = train_knn(X_train_sm, X_test_sm, y_train_sm, y_test_sm)\n",
    "y_smogn_knn_sfr, metrics_smogn_knn_sfr, train_loss_smogn_knn_sfr, test_loss_smogn_knn_sfr, k_vals_smogn_sfr = train_knn(X_train_sfr, X_test_sfr, y_train_sfr, y_test_sfr)\n",
    "y_smogn_knn_colour, metrics_smogn_knn_colour, train_loss_smogn_knn_colour, test_loss_smogn_knn_colour, k_vals_smogn_colour = train_knn(X_train_colour, X_test_colour, y_train_colour, y_test_colour)\n",
    "y_smogn_knn_sr, metrics_smogn_knn_sr, train_loss_smogn_knn_sr, test_loss_smogn_knn_sr, k_vals_smogn_sr = train_knn(X_train_sr, X_test_sr, y_train_sr, y_test_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35817319",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 5), sharey=False)\n",
    "axes = axes.flatten()\n",
    "\n",
    "properties = [\n",
    "    ('SM', 'Stellar Mass', y_test_sm, y_train_sm),\n",
    "    ('SFR', 'Star Formation Rate', y_test_sfr, y_train_sfr),\n",
    "    ('SR', 'Stellar Radius', y_test_sr, y_train_sr),\n",
    "    ('Colour', 'r - i', y_test_colour, y_train_colour)\n",
    "]\n",
    "\n",
    "for i, (prop, xlabel, ytrue_raw, ysmogn_raw) in enumerate(properties):\n",
    "    ax = axes[i]\n",
    "    ytrue_compare = ytrue_raw.flatten()\n",
    "    ysmogn = ysmogn_raw.flatten()\n",
    "\n",
    "    hist_true, bin_edges = np.histogram(ytrue_compare, bins=50)\n",
    "    hist_smogn, _ = np.histogram(ysmogn, bins=bin_edges)\n",
    "\n",
    "    ax.hist(ytrue_compare, bins=bin_edges, histtype='stepfilled',\n",
    "            color='mediumpurple', alpha=0.65, label='True', linewidth=0)\n",
    "\n",
    "    ax.step(bin_edges[:-1], hist_smogn, where='post', label='SMOGN',\n",
    "            color='black', lw=0.42)\n",
    "\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylim(0.5, max(hist_true.max(), hist_smogn.max()) * 3)\n",
    "    ax.set_xlabel(xlabel, fontsize=10)\n",
    "    ax.set_ylabel('# of central galaxies', fontsize=13)\n",
    "    ax.legend(loc='upper left', fontsize=7, framealpha=0.6)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--', which='both')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2fb3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract predictions from the new training function outputs (first element of tuple)\n",
    "properties = [\n",
    "    ('SM', 'Stellar Mass', y_test_sm, y_raw_nn_sm, y_raw_knn_sm, y_raw_et_sm,\n",
    "         y_smogn_nn_sm, y_smogn_knn_sm, y_smogn_et_sm),\n",
    "    ('SFR', 'Star Formation Rate', y_test_sfr, y_raw_nn_sfr, y_raw_knn_sfr, y_raw_et_sfr,\n",
    "         y_smogn_nn_sfr, y_smogn_knn_sfr, y_smogn_et_sfr),\n",
    "    ('SR', 'Stellar Radius', y_test_sr, y_raw_nn_sr, y_raw_knn_sr, y_raw_et_sr,\n",
    "         y_smogn_nn_sr, y_smogn_knn_sr, y_smogn_et_sr),\n",
    "    ('Colour', 'r - i', y_test_colour, y_raw_nn_colour, y_raw_knn_colour, y_raw_et_colour,\n",
    "         y_smogn_nn_colour, y_smogn_knn_colour, y_smogn_et_colour)\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 7), sharey='row')\n",
    "\n",
    "model_colors = {\n",
    "    'NN': 'cornflowerblue',\n",
    "    'kNN': 'deepskyblue',\n",
    "    'ERT': 'peru'\n",
    "}\n",
    "\n",
    "for col, (prop, xlabel, ytrue, nn_raw, knn_raw, ert_raw, nn_smogn, knn_smogn, ert_smogn) in enumerate(properties):\n",
    "    \n",
    "    # Raw models (top row)\n",
    "    ax_raw = axes[0, col]\n",
    "    hist_true, bins = np.histogram(ytrue.flatten(), bins=50)\n",
    "    ax_raw.hist(ytrue.flatten(), bins=bins, histtype='stepfilled', color='mediumpurple', alpha=0.65, label='True')\n",
    "    \n",
    "    for model_name, pred in zip(['NN', 'kNN', 'ERT'], [nn_raw, knn_raw, ert_raw]):\n",
    "        hist_pred, _ = np.histogram(pred.flatten(), bins=bins)\n",
    "        ax_raw.step(bins[:-1], hist_pred, where='post', color=model_colors[model_name], label=model_name, lw=2)\n",
    "    \n",
    "    ax_raw.set_yscale('log')\n",
    "    ax_raw.set_ylim(1, hist_true.max() * 3)\n",
    "    ax_raw.set_title(f'Raw models - {xlabel}', fontsize=12, fontweight='bold')\n",
    "    ax_raw.set_xlabel(xlabel, fontsize=11)\n",
    "    if col == 0:\n",
    "        ax_raw.set_ylabel('# of central galaxies', fontsize=11)\n",
    "    ax_raw.grid(True, alpha=0.3, linestyle='--', which='both')\n",
    "    \n",
    "    # SMOGN models (bottom row)\n",
    "    ax_smogn = axes[1, col]\n",
    "    hist_true, bins = np.histogram(ytrue.flatten(), bins=50)\n",
    "    ax_smogn.hist(ytrue.flatten(), bins=bins, histtype='stepfilled', color='mediumpurple', alpha=0.65, label='True')\n",
    "    \n",
    "    for model_name, pred in zip(['NN', 'kNN', 'ERT'], [nn_smogn, knn_smogn, ert_smogn]):\n",
    "        hist_pred, _ = np.histogram(pred.flatten(), bins=bins)\n",
    "        ax_smogn.step(bins[:-1], hist_pred, where='post', color=model_colors[model_name], label=model_name, lw=2)\n",
    "    \n",
    "    ax_smogn.set_yscale('log')\n",
    "    ax_smogn.set_ylim(1, hist_true.max() * 3)\n",
    "    ax_smogn.set_title(f'SMOGN models - {xlabel}', fontsize=12, fontweight='bold')\n",
    "    ax_smogn.set_xlabel(xlabel, fontsize=11)\n",
    "    if col == 0:\n",
    "        ax_smogn.set_ylabel('# of central galaxies', fontsize=11)\n",
    "    ax_smogn.grid(True, alpha=0.3, linestyle='--', which='both')\n",
    "\n",
    "# Add legends\n",
    "axes[0, 0].legend(fontsize=10, loc='upper right')\n",
    "axes[1, 0].legend(fontsize=10, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f808f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING CODE FOR TRAINING AND TESTING LOSS CURVES\n",
    "\n",
    "# Dictionary to store all loss histories\n",
    "loss_histories = {\n",
    "    'SM': {\n",
    "        'NN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'KNN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'ERT': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None}\n",
    "    },\n",
    "    'SFR': {\n",
    "        'NN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'KNN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'ERT': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None}\n",
    "    },\n",
    "    'Colour': {\n",
    "        'NN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'KNN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'ERT': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None}\n",
    "    },\n",
    "    'SR': {\n",
    "        'NN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'KNN': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None},\n",
    "        'ERT': {'raw_train': None, 'raw_test': None, 'smogn_train': None, 'smogn_test': None}\n",
    "    }\n",
    "}\n",
    "\n",
    "def plot_loss_curves(loss_histories):\n",
    "    \"\"\"\n",
    "    Plot training and testing loss curves for all targets and models\n",
    "    \"\"\"\n",
    "    targets = ['SM', 'SFR', 'Colour', 'SR']\n",
    "    target_names = ['Stellar Mass', 'Star Formation Rate', 'r - i', 'Stellar Radius']\n",
    "    models = ['NN', 'KNN', 'ERT']\n",
    "    model_names = ['Neural Network', 'KNN', 'Extra Trees']\n",
    "    \n",
    "    fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
    "    fig.suptitle('Training and Testing Loss Curves: Raw vs SMOGN', fontsize=16, y=0.995)\n",
    "    \n",
    "    for row, (target, target_name) in enumerate(zip(targets, target_names)):\n",
    "        for col, (model, model_name) in enumerate(zip(models, model_names)):\n",
    "            ax = axes[row, col]\n",
    "            \n",
    "            # Get loss histories\n",
    "            raw_train = loss_histories[target][model]['raw_train']\n",
    "            raw_test = loss_histories[target][model]['raw_test']\n",
    "            smogn_train = loss_histories[target][model]['smogn_train']\n",
    "            smogn_test = loss_histories[target][model]['smogn_test']\n",
    "            \n",
    "            if raw_train is not None and raw_test is not None:\n",
    "                # For NN, use epochs directly\n",
    "                if model == 'NN':\n",
    "                    x_raw = np.arange(len(raw_train))\n",
    "                    x_smogn = np.arange(len(smogn_train)) if smogn_train is not None else None\n",
    "                    xlabel = 'Epoch'\n",
    "                # For ERT, use number of estimators\n",
    "                elif model == 'ERT':\n",
    "                    x_raw = [10, 20, 50, 100, 150, 200][:len(raw_train)]\n",
    "                    x_smogn = [10, 20, 50, 100, 150, 200][:len(smogn_train)] if smogn_train is not None else None\n",
    "                    xlabel = 'Number of Estimators'\n",
    "                # For KNN, use k values\n",
    "                else:  # KNN\n",
    "                    x_raw = [3, 5, 7, 10, 15, 20, 30][:len(raw_train)]\n",
    "                    x_smogn = [3, 5, 7, 10, 15, 20, 30][:len(smogn_train)] if smogn_train is not None else None\n",
    "                    xlabel = 'k (Number of Neighbors)'\n",
    "                \n",
    "                # Plot raw model\n",
    "                ax.plot(x_raw, raw_train, label='Raw Train', color='#1f77b4', linewidth=2, linestyle='-')\n",
    "                ax.plot(x_raw, raw_test, label='Raw Test', color='#1f77b4', linewidth=2, linestyle='--')\n",
    "                \n",
    "                # Plot SMOGN model\n",
    "                if smogn_train is not None and smogn_test is not None:\n",
    "                    ax.plot(x_smogn, smogn_train, label='SMOGN Train', color='#ff7f0e', linewidth=2, linestyle='-')\n",
    "                    ax.plot(x_smogn, smogn_test, label='SMOGN Test', color='#ff7f0e', linewidth=2, linestyle='--')\n",
    "                \n",
    "                ax.set_xlabel(xlabel, fontsize=11)\n",
    "                ax.set_ylabel('MSE Loss', fontsize=11)\n",
    "                \n",
    "                # Set title\n",
    "                if row == 0:\n",
    "                    ax.set_title(f'{model_name}', fontsize=12, fontweight='bold')\n",
    "                \n",
    "                # Add target name on the left\n",
    "                if col == 0:\n",
    "                    ax.text(-0.35, 0.5, target_name, transform=ax.transAxes, \n",
    "                           fontsize=12, fontweight='bold', rotation=90, \n",
    "                           verticalalignment='center', horizontalalignment='center')\n",
    "                \n",
    "                ax.legend(loc='best', fontsize=9)\n",
    "                ax.grid(True, alpha=0.3)\n",
    "                \n",
    "                # Use log scale for y-axis if losses vary widely\n",
    "                if model == 'NN':\n",
    "                    ax.set_yscale('log')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, 'No data available', \n",
    "                       transform=ax.transAxes, ha='center', va='center')\n",
    "                ax.set_xlabel(xlabel if model == 'NN' else ('Number of Estimators' if model == 'ERT' else 'k'), fontsize=11)\n",
    "                ax.set_ylabel('MSE Loss', fontsize=11)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "loss_histories['SM']['NN']['raw_train'] = train_loss_raw_nn_sm\n",
    "loss_histories['SM']['NN']['raw_test'] = test_loss_raw_nn_sm\n",
    "loss_histories['SM']['NN']['smogn_train'] = train_loss_smogn_nn_sm\n",
    "loss_histories['SM']['NN']['smogn_test'] = test_loss_smogn_nn_sm\n",
    "\n",
    "loss_histories['SM']['KNN']['raw_train'] = train_loss_raw_knn_sm\n",
    "loss_histories['SM']['KNN']['raw_test'] = test_loss_raw_knn_sm\n",
    "loss_histories['SM']['KNN']['smogn_train'] = train_loss_smogn_knn_sm\n",
    "loss_histories['SM']['KNN']['smogn_test'] = test_loss_smogn_knn_sm\n",
    "\n",
    "loss_histories['SM']['ERT']['raw_train'] = train_loss_raw_et_sm\n",
    "loss_histories['SM']['ERT']['raw_test'] = test_loss_raw_et_sm\n",
    "loss_histories['SM']['ERT']['smogn_train'] = train_loss_smogn_et_sm\n",
    "loss_histories['SM']['ERT']['smogn_test'] = test_loss_smogn_et_sm\n",
    "\n",
    "loss_histories['SFR']['NN']['raw_train'] = train_loss_raw_nn_sfr\n",
    "loss_histories['SFR']['NN']['raw_test'] = test_loss_raw_nn_sfr\n",
    "loss_histories['SFR']['NN']['smogn_train'] = train_loss_smogn_nn_sfr\n",
    "loss_histories['SFR']['NN']['smogn_test'] = test_loss_smogn_nn_sfr\n",
    "\n",
    "loss_histories['SFR']['KNN']['raw_train'] = train_loss_raw_knn_sfr\n",
    "loss_histories['SFR']['KNN']['raw_test'] = test_loss_raw_knn_sfr\n",
    "loss_histories['SFR']['KNN']['smogn_train'] = train_loss_smogn_knn_sfr\n",
    "loss_histories['SFR']['KNN']['smogn_test'] = test_loss_smogn_knn_sfr\n",
    "\n",
    "loss_histories['SFR']['ERT']['raw_train'] = train_loss_raw_et_sfr\n",
    "loss_histories['SFR']['ERT']['raw_test'] = test_loss_raw_et_sfr\n",
    "loss_histories['SFR']['ERT']['smogn_train'] = train_loss_smogn_et_sfr\n",
    "loss_histories['SFR']['ERT']['smogn_test'] = test_loss_smogn_et_sfr\n",
    "\n",
    "loss_histories['Colour']['NN']['raw_train'] = train_loss_raw_nn_colour\n",
    "loss_histories['Colour']['NN']['raw_test'] = test_loss_raw_nn_colour\n",
    "loss_histories['Colour']['NN']['smogn_train'] = train_loss_smogn_nn_colour\n",
    "loss_histories['Colour']['NN']['smogn_test'] = test_loss_smogn_nn_colour\n",
    "\n",
    "loss_histories['Colour']['KNN']['raw_train'] = train_loss_raw_knn_colour\n",
    "loss_histories['Colour']['KNN']['raw_test'] = test_loss_raw_knn_colour\n",
    "loss_histories['Colour']['KNN']['smogn_train'] = train_loss_smogn_knn_colour\n",
    "loss_histories['Colour']['KNN']['smogn_test'] = test_loss_smogn_knn_colour\n",
    "\n",
    "loss_histories['Colour']['ERT']['raw_train'] = train_loss_raw_et_colour\n",
    "loss_histories['Colour']['ERT']['raw_test'] = test_loss_raw_et_colour\n",
    "loss_histories['Colour']['ERT']['smogn_train'] = train_loss_smogn_et_colour\n",
    "loss_histories['Colour']['ERT']['smogn_test'] = test_loss_smogn_et_colour\n",
    "\n",
    "loss_histories['SR']['NN']['raw_train'] = train_loss_raw_nn_sr\n",
    "loss_histories['SR']['NN']['raw_test'] = test_loss_raw_nn_sr\n",
    "loss_histories['SR']['NN']['smogn_train'] = train_loss_smogn_nn_sr\n",
    "loss_histories['SR']['NN']['smogn_test'] = test_loss_smogn_nn_sr\n",
    "\n",
    "loss_histories['SR']['KNN']['raw_train'] = train_loss_raw_knn_sr\n",
    "loss_histories['SR']['KNN']['raw_test'] = test_loss_raw_knn_sr\n",
    "loss_histories['SR']['KNN']['smogn_train'] = train_loss_smogn_knn_sr\n",
    "loss_histories['SR']['KNN']['smogn_test'] = test_loss_smogn_knn_sr\n",
    "\n",
    "loss_histories['SR']['ERT']['raw_train'] = train_loss_raw_et_sr\n",
    "loss_histories['SR']['ERT']['raw_test'] = test_loss_raw_et_sr\n",
    "loss_histories['SR']['ERT']['smogn_train'] = train_loss_smogn_et_sr\n",
    "loss_histories['SR']['ERT']['smogn_test'] = test_loss_smogn_et_sr\n",
    "\n",
    "plot_loss_curves(loss_histories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d51693",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_names = ['Stellar Mass', 'SFR', 'Radius', 'Colour']\n",
    "model_names = ['NN', 'kNN', 'ERT']\n",
    "model_colors = {\n",
    "    'NN': 'dodgerblue',\n",
    "    'kNN': 'deepskyblue',\n",
    "    'ERT': 'peru'\n",
    "}\n",
    "\n",
    "# Metrics dictionaries - these work with the new training functions\n",
    "metrics_raw = {\n",
    "    'NN':   [metrics_raw_nn_sm, metrics_raw_nn_sfr, metrics_raw_nn_sr, metrics_raw_nn_colour],\n",
    "    'kNN':  [metrics_raw_knn_sm, metrics_raw_knn_sfr, metrics_raw_knn_sr, metrics_raw_knn_colour],\n",
    "    'ERT':  [metrics_raw_et_sm, metrics_raw_et_sfr, metrics_raw_et_sr, metrics_raw_et_colour]\n",
    "}\n",
    "metrics_smogn = {\n",
    "    'NN':   [metrics_smogn_nn_sm, metrics_smogn_nn_sfr, metrics_smogn_nn_sr, metrics_smogn_nn_colour],\n",
    "    'kNN':  [metrics_smogn_knn_sm, metrics_smogn_knn_sfr, metrics_smogn_knn_sr, metrics_smogn_knn_colour],\n",
    "    'ERT':  [metrics_smogn_et_sm, metrics_smogn_et_sfr, metrics_smogn_et_sr, metrics_smogn_et_colour]\n",
    "}\n",
    "\n",
    "# Extract Pearson correlations\n",
    "pearson_raw = np.array([[metrics_raw[model][i]['target_0']['Pearson_r'] for model in model_names] for i in range(4)])\n",
    "pearson_smogn = np.array([[metrics_smogn[model][i]['target_0']['Pearson_r'] for model in model_names] for i in range(4)])\n",
    "\n",
    "# Plot Pearson correlations\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
    "for ax, pearson, title in zip(\n",
    "    axs, [pearson_raw, pearson_smogn], \n",
    "    ['Pearson Correlation: Raw Models', 'Pearson Correlation: SMOGN Models']\n",
    "):\n",
    "    for j, model in enumerate(model_names):\n",
    "        ax.plot(property_names, pearson[:, j], marker='s', markersize=8, \n",
    "                color=model_colors[model], label=model, linewidth=2.5)\n",
    "    ax.set_ylabel('Pearson Correlation', fontsize=11)\n",
    "    ax.set_title(title, fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='best', fontsize=10)\n",
    "    ax.grid(True, ls='--', alpha=0.4)\n",
    "    ax.set_ylim([pearson.min() - 0.05, 1.0])\n",
    "axs[0].set_xlabel('Property', fontsize=11)\n",
    "axs[1].set_xlabel('Property', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract K-S statistics\n",
    "ks_raw = np.array([[metrics_raw[model][i]['target_0']['KS_statistic'] for model in model_names] for i in range(4)])\n",
    "ks_smogn = np.array([[metrics_smogn[model][i]['target_0']['KS_statistic'] for model in model_names] for i in range(4)])\n",
    "\n",
    "# Plot K-S test statistics\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 7), sharey=False)\n",
    "for idx, prop in enumerate(property_names):\n",
    "    ax = axs[idx // 2, idx % 2]\n",
    "    ax.plot(model_names, ks_raw[idx], marker='o', markersize=8, \n",
    "            label='Raw', color='dodgerblue', linewidth=2.5)\n",
    "    ax.plot(model_names, ks_smogn[idx], marker='s', markersize=8, \n",
    "            label='SMOGN', color='coral', linewidth=2.5)\n",
    "    ax.set_title(f'K-S Test: {prop}', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('KS Statistic (D)', fontsize=11)\n",
    "    ax.set_xlabel('Model', fontsize=11)\n",
    "    ax.legend(fontsize=10, loc='best')\n",
    "    ax.grid(True, alpha=0.4, ls='--')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc296d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_names = ['Stellar Mass', 'sSFR', 'Radius', 'Colour']\n",
    "\n",
    "true_test = [y_test_sm.flatten(), y_test_sfr.flatten(), y_test_sr.flatten(), y_test_colour.flatten()]\n",
    "pred_raw  = [y_raw_nn_sm.flatten(), y_raw_nn_sfr.flatten(), y_raw_nn_sr.flatten(), y_raw_nn_colour.flatten()]\n",
    "pred_smogn = [y_smogn_nn_sm.flatten(), y_smogn_nn_sfr.flatten(), y_smogn_nn_sr.flatten(), y_smogn_nn_colour.flatten()]\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(10, 12), sharex=False, sharey=False)\n",
    "vmin, vmax = 0., 1.\n",
    "for i, pname in enumerate(property_names):\n",
    "\n",
    "    x = true_test[i]\n",
    "    y_raw = pred_raw[i]\n",
    "    y_smogn = pred_smogn[i]\n",
    "    for j, (y_pred, title) in enumerate(zip([y_raw, y_smogn], ['Raw NN', 'SMOGN NN'])):\n",
    "        ax = axes[i, j]\n",
    "        # Density scatter plot\n",
    "        hb = ax.hexbin(x, y_pred, gridsize=60, cmap='turbo', bins='log')\n",
    "        # Diagonal reference\n",
    "        ax.plot([x.min(), x.max()], [x.min(), x.max()], 'k--', lw=2, label='True x True')\n",
    "        ax.set_xlim(x.min(), x.max())\n",
    "        ax.set_ylim(x.min(), x.max())\n",
    "        ax.set_title(f'{title}: {pname}')\n",
    "        ax.set_xlabel(f'True {pname}')\n",
    "        ax.set_ylabel(f'Predicted {pname}')\n",
    "        if j == 1:\n",
    "            # Color bar for the right column (once per row)\n",
    "            cb = fig.colorbar(hb, ax=ax)\n",
    "        ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
