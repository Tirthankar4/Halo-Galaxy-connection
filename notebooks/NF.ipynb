{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89bfede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import smogn\n",
    "import h5py\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.stats import pearsonr, ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d2c24a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 3.*10**8\n",
    "\n",
    "with h5py.File('data/groups_090.hdf5', 'r') as f:\n",
    "    # Positions, velocities and masses of the halos\n",
    "    M_h =   f['Group/Group_M_Crit200'][:]*1e10      #Msun/h\n",
    "    R_h =   f['Group/Group_R_Crit200'][:]/c         #kpc/h\n",
    "    V_h  =  f['Group/GroupVel'][:]                  #km/s\n",
    "    V_h =   np.linalg.norm(V_h, axis = 1)\n",
    "    ID_r =  f['Group/GroupFirstSub'][:] #Contains halos without gals as this number = -1\n",
    "    ID_h =  np.arange(0, M_h.shape[0], 1, dtype = float) #It is the ID of the halos, to match the gal cat\n",
    "\n",
    "    # Positions, stellar masses,  of the galaxies\n",
    "    SM     = f['Subhalo/SubhaloMassType'][:, 4]*1e10 #Msun/h\n",
    "    SFR    = f['Subhalo/SubhaloSFR'][:]*1e10 #Msun/yr\n",
    "    SR = f['Subhalo/SubhaloHalfmassRadType'][:, 4]\n",
    "    Colour = f['Subhalo/SubhaloStellarPhotometrics'][:, 4] - f['Subhalo/SubhaloStellarPhotometrics'][:, 5] #g-r \n",
    "    ID_g = np.array(f['Subhalo/SubhaloGrNr']) #Gals IDs\n",
    "\n",
    "indexes = np.where( ID_r != -1)[0]\n",
    "M_h = M_h[indexes]\n",
    "R_h = R_h[indexes]\n",
    "V_h = V_h[indexes]\n",
    "ID_h = ID_h[indexes]\n",
    "\n",
    "# Halo catalog\n",
    "data = np.array( [ M_h, R_h, V_h, ID_h ] ).T\n",
    "columns = [ 'M_h', 'R_h', 'V_h', 'ID' ] \n",
    "halos = pd.DataFrame(data = data, columns = columns)\n",
    "\n",
    "indexes = np.where(SM > 0)[0]\n",
    "SM = SM[indexes]\n",
    "SFR = SFR[indexes]\n",
    "SR = SR[indexes]\n",
    "Colour = Colour[indexes]\n",
    "ID_g = ID_g[indexes]\n",
    "\n",
    "#Galaxy catalog\n",
    "data = np.array([SM, SFR, Colour, SR, ID_g]).T\n",
    "columns = ['SM', 'SFR', 'Colour', 'SR', 'ID']\n",
    "gals = pd.DataFrame(data=data, columns=columns)\n",
    "\n",
    "gals = gals.drop_duplicates(subset = ['ID'], keep = 'first')\n",
    "\n",
    "gals['SFR'] = gals['SFR'].replace(0, 1)\n",
    "gals['SFR'] = np.log10(gals['SFR'])\n",
    "gals.loc[gals['SFR'] == 0, 'SFR'] = np.random.normal(8.0, 0.5, len(gals.loc[gals['SFR'] == 0]))\n",
    "#gals.shape\n",
    "\n",
    "#SM.shape, M_h.shape\n",
    "\n",
    "df = pd.merge(left = halos, right = gals, left_on = 'ID', right_on = 'ID')\n",
    "\n",
    "df['M_h'] = np.log10(df['M_h'])\n",
    "df['R_h'] = np.log10(df['R_h'])\n",
    "df['V_h'] = np.log10(df['V_h'])\n",
    "\n",
    "df['SM']  = np.log10(df['SM'])\n",
    "#df['SR']  = np.log10(df['SR'] + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6033095f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_h</th>\n",
       "      <th>R_h</th>\n",
       "      <th>V_h</th>\n",
       "      <th>ID</th>\n",
       "      <th>SM</th>\n",
       "      <th>SFR</th>\n",
       "      <th>Colour</th>\n",
       "      <th>SR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "      <td>1522.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.708978</td>\n",
       "      <td>-6.696243</td>\n",
       "      <td>2.141821</td>\n",
       "      <td>1105.073587</td>\n",
       "      <td>7.862840</td>\n",
       "      <td>8.298691</td>\n",
       "      <td>0.461720</td>\n",
       "      <td>3.470842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.577714</td>\n",
       "      <td>0.192572</td>\n",
       "      <td>0.242986</td>\n",
       "      <td>1305.457871</td>\n",
       "      <td>0.992273</td>\n",
       "      <td>0.702191</td>\n",
       "      <td>0.135016</td>\n",
       "      <td>3.823537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.159530</td>\n",
       "      <td>-7.212732</td>\n",
       "      <td>0.851517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.240346</td>\n",
       "      <td>6.612498</td>\n",
       "      <td>-0.485580</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.342783</td>\n",
       "      <td>-6.818321</td>\n",
       "      <td>2.001680</td>\n",
       "      <td>380.250000</td>\n",
       "      <td>7.110663</td>\n",
       "      <td>7.828316</td>\n",
       "      <td>0.432980</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.605010</td>\n",
       "      <td>-6.730893</td>\n",
       "      <td>2.158645</td>\n",
       "      <td>785.500000</td>\n",
       "      <td>7.534524</td>\n",
       "      <td>8.203735</td>\n",
       "      <td>0.476573</td>\n",
       "      <td>3.179318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.983194</td>\n",
       "      <td>-6.604847</td>\n",
       "      <td>2.310032</td>\n",
       "      <td>1370.750000</td>\n",
       "      <td>8.308563</td>\n",
       "      <td>8.658343</td>\n",
       "      <td>0.528253</td>\n",
       "      <td>5.235649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.653268</td>\n",
       "      <td>-5.714802</td>\n",
       "      <td>2.750748</td>\n",
       "      <td>17953.000000</td>\n",
       "      <td>11.630214</td>\n",
       "      <td>10.718828</td>\n",
       "      <td>0.807940</td>\n",
       "      <td>32.569843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               M_h          R_h          V_h            ID           SM  \\\n",
       "count  1522.000000  1522.000000  1522.000000   1522.000000  1522.000000   \n",
       "mean     10.708978    -6.696243     2.141821   1105.073587     7.862840   \n",
       "std       0.577714     0.192572     0.242986   1305.457871     0.992273   \n",
       "min       9.159530    -7.212732     0.851517      0.000000     6.240346   \n",
       "25%      10.342783    -6.818321     2.001680    380.250000     7.110663   \n",
       "50%      10.605010    -6.730893     2.158645    785.500000     7.534524   \n",
       "75%      10.983194    -6.604847     2.310032   1370.750000     8.308563   \n",
       "max      13.653268    -5.714802     2.750748  17953.000000    11.630214   \n",
       "\n",
       "               SFR       Colour           SR  \n",
       "count  1522.000000  1522.000000  1522.000000  \n",
       "mean      8.298691     0.461720     3.470842  \n",
       "std       0.702191     0.135016     3.823537  \n",
       "min       6.612498    -0.485580     0.000000  \n",
       "25%       7.828316     0.432980     0.000000  \n",
       "50%       8.203735     0.476573     3.179318  \n",
       "75%       8.658343     0.528253     5.235649  \n",
       "max      10.718828     0.807940    32.569843  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6460a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5), sharey = True, dpi = 100)\n",
    "\n",
    "fig.suptitle('Halo properties')\n",
    "\n",
    "axs[0].hist(df['M_h'], bins = 40)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel('M_h')\n",
    "axs[0].set_ylabel('# halos')\n",
    "\n",
    "axs[1].hist(df['R_h'], bins = 40)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('R_h')\n",
    "\n",
    "axs[2].hist(df['V_h'], bins = 40)\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlabel('V_h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize = (15, 5), sharey = True, dpi = 100)\n",
    "\n",
    "fig.suptitle('Galaxy properties')\n",
    "\n",
    "axs[0].hist(df['SM'], bins = 40)\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_xlabel(r'$M_{\\star}$')\n",
    "axs[0].set_ylabel('# halos')\n",
    "\n",
    "axs[1].hist(df['Colour'], bins = 40)\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_xlabel('Color')\n",
    "\n",
    "axs[2].hist(df['SFR'], bins = 40)\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_xlabel('SFR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcb4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_heatmap(df):\n",
    "    correlations = df.corr(method = 'pearson')\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (8,8))\n",
    "    sns.heatmap(correlations, vmax = 1.0, center = 0, fmt = '.4f',\n",
    "                square = True, linewidths = .5, annot = True, \n",
    "                cbar_kws = {\"shrink\": .82})\n",
    "    plt.title('Pearson correlation Heatmap')\n",
    "    plt.show()\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "correlation_heatmap(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65ac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['M_h'], df['SM'], s=1)\n",
    "plt.xlabel(r'$M_{\\mathrm{halo}} \\,/\\, M_{\\odot}$')\n",
    "plt.ylabel(r'$M_{\\star} \\,/\\, M_{\\odot}$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d693365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M_h</th>\n",
       "      <th>R_h</th>\n",
       "      <th>V_h</th>\n",
       "      <th>ID</th>\n",
       "      <th>SM</th>\n",
       "      <th>SFR</th>\n",
       "      <th>Colour</th>\n",
       "      <th>SR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.653268</td>\n",
       "      <td>-5.714802</td>\n",
       "      <td>1.431432</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.630214</td>\n",
       "      <td>8.243891</td>\n",
       "      <td>0.762205</td>\n",
       "      <td>30.098984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.281644</td>\n",
       "      <td>-5.838683</td>\n",
       "      <td>1.751035</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.370838</td>\n",
       "      <td>7.339507</td>\n",
       "      <td>0.762400</td>\n",
       "      <td>9.118227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.303414</td>\n",
       "      <td>-5.831418</td>\n",
       "      <td>2.276157</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.220836</td>\n",
       "      <td>8.386258</td>\n",
       "      <td>0.748251</td>\n",
       "      <td>14.697025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.185764</td>\n",
       "      <td>-5.870649</td>\n",
       "      <td>1.467040</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.512475</td>\n",
       "      <td>7.148647</td>\n",
       "      <td>0.802225</td>\n",
       "      <td>5.556552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.200743</td>\n",
       "      <td>-5.865651</td>\n",
       "      <td>2.303855</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.332070</td>\n",
       "      <td>8.381227</td>\n",
       "      <td>0.760628</td>\n",
       "      <td>19.559307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         M_h       R_h       V_h   ID         SM       SFR    Colour  \\\n",
       "0  13.653268 -5.714802  1.431432  0.0  11.630214  8.243891  0.762205   \n",
       "1  13.281644 -5.838683  1.751035  1.0  11.370838  7.339507  0.762400   \n",
       "2  13.303414 -5.831418  2.276157  2.0  11.220836  8.386258  0.748251   \n",
       "3  13.185764 -5.870649  1.467040  3.0  11.512475  7.148647  0.802225   \n",
       "4  13.200743 -5.865651  2.303855  4.0  11.332070  8.381227  0.760628   \n",
       "\n",
       "          SR  \n",
       "0  30.098984  \n",
       "1   9.118227  \n",
       "2  14.697025  \n",
       "3   5.556552  \n",
       "4  19.559307  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5352b43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "halos = df[['M_h', 'R_h', 'V_h']]\n",
    "gals = df[['SM', 'SFR', 'Colour', 'SR']]\n",
    "\n",
    "halos_train, halos_test, gals_train, gals_test = train_test_split(halos, gals, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11abe066",
   "metadata": {},
   "outputs": [],
   "source": [
    "halos_scalar = StandardScaler()\n",
    "gals_scalar = StandardScaler()\n",
    "\n",
    "halos_train = halos_scalar.fit_transform(halos_train)\n",
    "halos_test = halos_scalar.transform(halos_test)\n",
    "gals_train = gals_scalar.fit_transform(gals_train)\n",
    "gals_test = gals_scalar.transform(gals_test)\n",
    "\n",
    "halos_train_scaled = torch.tensor(halos_train, dtype=torch.float32)\n",
    "halos_test_scaled = torch.tensor(halos_test, dtype=torch.float32)\n",
    "gals_train_scaled = torch.tensor(gals_train, dtype=torch.float32)\n",
    "gals_test_scaled = torch.tensor(gals_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d997f87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.distributions.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d92652ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "halos_dim = 3\n",
    "gals_dim = 4\n",
    "\n",
    "dist_base = dist.Normal(torch.zeros(halos_dim), torch.ones(halos_dim) * 0.2).to_event(1)\n",
    "x1_transform = T.spline(halos_dim)\n",
    "x3_transform = T.affine_coupling(halos_dim)\n",
    "dist_x1 = dist.TransformedDistribution(dist_base, [x1_transform, x3_transform]) \n",
    "\n",
    "x2_transform = T.conditional_spline(gals_dim, context_dim=halos_dim)\n",
    "dist_x2_given_x1 = dist.ConditionalTransformedDistribution(dist.Normal(torch.zeros(gals_dim), \n",
    "                                            torch.ones(gals_dim) * 0.2).to_event(1), [x2_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0c52d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 167.45999145507812\n",
      "step: 100, loss: 21.301294326782227\n",
      "step: 200, loss: 15.950521469116211\n",
      "step: 300, loss: 14.078961372375488\n",
      "step: 400, loss: 15.332249641418457\n",
      "step: 500, loss: 13.889490127563477\n",
      "step: 600, loss: 14.127150535583496\n",
      "step: 700, loss: 14.043694496154785\n",
      "step: 800, loss: 14.004009246826172\n",
      "step: 900, loss: 13.253273963928223\n",
      "step: 1000, loss: 16.792861938476562\n",
      "step: 1100, loss: 12.345771789550781\n",
      "step: 1200, loss: 12.496703147888184\n",
      "step: 1300, loss: 12.160226821899414\n"
     ]
    }
   ],
   "source": [
    "steps = 1301\n",
    "modules = torch.nn.ModuleList([x1_transform, x3_transform, x2_transform])\n",
    "optimizer = torch.optim.Adam(modules.parameters(), lr=1e-2)\n",
    "\n",
    "running_loss = 0\n",
    "for step in range(steps+1):\n",
    "    optimizer.zero_grad()\n",
    "    ln_p_x1 = dist_x1.log_prob(halos_train_scaled)\n",
    "    ln_p_x2_given_x1 = dist_x2_given_x1.condition(halos_train_scaled.detach()).log_prob(gals_train_scaled.detach())\n",
    "    loss = -(ln_p_x1 + ln_p_x2_given_x1).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    dist_x1.clear_cache()\n",
    "    dist_x2_given_x1.clear_cache()\n",
    "    running_loss += 10**loss.item()\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print('step: {}, loss: {}'.format(step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1902e1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "halos_flow = dist_x1.sample(torch.Size([int(1e3)]))\n",
    "\n",
    "gals_flow = dist_x2_given_x1.condition(halos_flow).sample(torch.Size([int(1e3)]))\n",
    "\n",
    "halos_flow = halos_scalar.inverse_transform(halos_flow).flatten()\n",
    "gals_flow = gals_scalar.inverse_transform(gals_flow).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf1e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kw = dict(width_ratios=[2, 1], height_ratios=[1, 2])\n",
    "\n",
    "fig, axd = plt.subplot_mosaic([['upper left', 'upper right'], \n",
    "                               ['lower left', 'lower right']],\n",
    "                              gridspec_kw=gs_kw, figsize=(7, 7), \n",
    "                              constrained_layout=True)\n",
    "\n",
    "xlims = [9, 14]\n",
    "ylims = [6, 12]\n",
    "\n",
    "# Note: halos_train and gals_train were overwritten by scaling earlier (they are numpy arrays),\n",
    "# so inverse-transform them back to the original scale for plotting.\n",
    "halos_train_unscaled = halos_scalar.inverse_transform(halos_train)\n",
    "gals_train_unscaled  = gals_scalar.inverse_transform(gals_train)\n",
    "\n",
    "# Resample flow outputs and convert to numpy, then inverse-transform\n",
    "with torch.no_grad():\n",
    "    halos_flow_t = dist_x1.sample(torch.Size([int(1e3)]))\n",
    "    gals_flow_t = dist_x2_given_x1.condition(halos_flow_t).sample(torch.Size([int(1e3)]))\n",
    "\n",
    "halos_flow_np = halos_flow_t.detach().cpu().numpy()\n",
    "gals_flow_np  = gals_flow_t.detach().cpu().numpy()\n",
    "\n",
    "halos_flow_unscaled = halos_scalar.inverse_transform(halos_flow_np)\n",
    "gals_flow_unscaled  = gals_scalar.inverse_transform(gals_flow_np)\n",
    "\n",
    "axd['upper right'].remove()\n",
    "\n",
    "ax = axd['lower left']\n",
    "ax.scatter(halos_train_unscaled[:, 0], gals_train_unscaled[:, 0], s=2, alpha=0.6, label='data', color='firebrick')\n",
    "ax.scatter(halos_flow_unscaled[:, 0], gals_flow_unscaled[:, 0], s=2, alpha=0.6, label='flow', color='C0')\n",
    "ax.set_xlabel(r'$\\mathrm{log_{10}}(M_{\\mathrm{halo}} \\,/\\, M_{\\odot})$')\n",
    "ax.set_ylabel(r'$\\mathrm{log_{10}}(M_{\\star} \\,/\\, M_{\\odot})$')\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.legend()\n",
    "\n",
    "ax = axd['upper left']    \n",
    "sns.kdeplot(halos_train_unscaled[:, 0], ax=ax, color='firebrick')\n",
    "sns.kdeplot(halos_flow_unscaled[:, 0], ax=ax, color='C0')\n",
    "ax.set_xlim(xlims)\n",
    "\n",
    "ax = axd['lower right']    \n",
    "sns.kdeplot(y=gals_train_unscaled[:, 0], ax=ax, color='firebrick')\n",
    "sns.kdeplot(y=gals_flow_unscaled[:, 0], ax=ax, color='C0')\n",
    "ax.set_ylim(ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91eac35f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Log-Likelihood (NLL): 8.628353118896484\n"
     ]
    }
   ],
   "source": [
    "ln_p_x1_test = dist_x1.log_prob(halos_test_scaled)\n",
    "\n",
    "ln_p_x2_given_x1_test = dist_x2_given_x1.condition(halos_test_scaled).log_prob(gals_test_scaled)\n",
    "\n",
    "log_likelihood = (ln_p_x1_test + ln_p_x2_given_x1_test).mean()\n",
    "\n",
    "nll = -(ln_p_x1_test + ln_p_x2_given_x1_test).mean()\n",
    "\n",
    "print(\"Negative Log-Likelihood (NLL):\", nll.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6ab5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kw = dict(width_ratios=[2, 1], height_ratios=[1, 2])\n",
    "\n",
    "fig, axd = plt.subplot_mosaic([['upper left', 'upper right'], \n",
    "                               ['lower left', 'lower right']],\n",
    "                              gridspec_kw=gs_kw, figsize=(7, 7), \n",
    "                              constrained_layout=True)\n",
    "\n",
    "xlims = [9, 14]\n",
    "ylims = [6, 12]\n",
    "\n",
    "# Note: halos_test and gals_test were overwritten by scaling earlier (they are numpy arrays),\n",
    "# so inverse-transform them back to the original scale for plotting.\n",
    "halos_test_unscaled = halos_scalar.inverse_transform(halos_test)\n",
    "gals_test_unscaled  = gals_scalar.inverse_transform(gals_test)\n",
    "\n",
    "# Resample flow outputs and convert to numpy, then inverse-transform\n",
    "with torch.no_grad():\n",
    "    halos_flow_t = dist_x1.sample(torch.Size([int(1e3)]))\n",
    "    gals_flow_t = dist_x2_given_x1.condition(halos_flow_t).sample(torch.Size([int(1e3)]))\n",
    "\n",
    "halos_flow_np = halos_flow_t.detach().cpu().numpy()\n",
    "gals_flow_np  = gals_flow_t.detach().cpu().numpy()\n",
    "\n",
    "halos_flow_unscaled = halos_scalar.inverse_transform(halos_flow_np)\n",
    "gals_flow_unscaled  = gals_scalar.inverse_transform(gals_flow_np)\n",
    "\n",
    "axd['upper right'].remove()\n",
    "\n",
    "ax = axd['lower left']\n",
    "ax.scatter(halos_test_unscaled[:, 0], gals_test_unscaled[:, 0], s=2, alpha=0.6, label='data', color='firebrick')\n",
    "ax.scatter(halos_flow_unscaled[:, 0], gals_flow_unscaled[:, 0], s=2, alpha=0.6, label='flow', color='C0')\n",
    "ax.set_xlabel(r'$\\mathrm{log_{10}}(M_{\\mathrm{halo}} \\,/\\, M_{\\odot})$')\n",
    "ax.set_ylabel(r'$\\mathrm{log_{10}}(M_{\\star} \\,/\\, M_{\\odot})$')\n",
    "ax.set_xlim(xlims)\n",
    "ax.set_ylim(ylims)\n",
    "ax.legend()\n",
    "\n",
    "ax = axd['upper left']    \n",
    "sns.kdeplot(halos_test_unscaled[:, 0], ax=ax, color='firebrick')\n",
    "sns.kdeplot(halos_flow_unscaled[:, 0], ax=ax, color='C0')\n",
    "ax.set_xlim(xlims)\n",
    "\n",
    "ax = axd['lower right']    \n",
    "sns.kdeplot(y=gals_test_unscaled[:, 0], ax=ax, color='firebrick')\n",
    "sns.kdeplot(y=gals_flow_unscaled[:, 0], ax=ax, color='C0')\n",
    "ax.set_ylim(ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20336c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_kw = dict(width_ratios=[2, 1], height_ratios=[1, 2])\n",
    "\n",
    "fig, axd = plt.subplot_mosaic([['upper left', 'upper right'], \n",
    "                               ['lower left', 'lower right']],\n",
    "                              gridspec_kw=gs_kw, figsize=(7, 7), \n",
    "                              constrained_layout=True)\n",
    "\n",
    "axd['upper right'].remove()\n",
    "axd['upper left'].remove()\n",
    "xlims = [9, 14]\n",
    "ylims = [6, 12]\n",
    "\n",
    "hmasses = [10, 10.5, 11, 11.5, 12, 12.5]\n",
    "cmap = plt.colormaps['Spectral']  # Fixed deprecated get_cmap\n",
    "means_raw = halos_scalar.mean_\n",
    "\n",
    "for i, hmass in enumerate(hmasses):\n",
    "    # Choose a color from the colormap\n",
    "    color = cmap(i / len(hmasses))\n",
    "    \n",
    "    # Generate 1000 halo samples with fixed hmass but mean Rh and Vh\n",
    "    N = int(1e3)\n",
    "    template = np.tile(means_raw, (N, 1))  # Shape: (1000, 3)\n",
    "    template[:, 0] = hmass  # Set the first column (M_h) to the desired hmass\n",
    "    \n",
    "    # Scale with the halo scaler and convert to torch\n",
    "    # Convert to DataFrame with correct column names (with underscores!)\n",
    "    template_df = pd.DataFrame(template, columns=['M_h', 'R_h', 'V_h'])\n",
    "    halos_cond_scaled = halos_scalar.transform(template_df)\n",
    "    halos_cond_t = torch.tensor(halos_cond_scaled, dtype=torch.float32)\n",
    "    \n",
    "    # Generate galaxies conditioned on this halo vector\n",
    "    gals_flow_t = dist_x2_given_x1.condition(halos_cond_t).sample(torch.Size([N]))\n",
    "    \n",
    "    # Inverse-transform for plotting (use only the mass columns)\n",
    "    halos_mass = halos_scalar.inverse_transform(halos_cond_t.detach().cpu().numpy())[:, 0]\n",
    "    gals_mass = gals_scalar.inverse_transform(gals_flow_t.detach().cpu().numpy())[:, 0]\n",
    "\n",
    "    # Plot the conditioned samples\n",
    "    ax = axd['lower left']\n",
    "    ax.scatter(halos_mass, gals_mass, s=2, alpha=0.6, label=hmass, color=color)\n",
    "    # Use raw string (r'') to fix invalid escape sequence warning\n",
    "    ax.set_xlabel(r'$\\mathrm{log_{10}}(M_{\\mathrm{halo}} \\,/\\, \\mathrm{M_{\\odot}})$')\n",
    "    ax.set_ylabel(r'$\\mathrm{log_{10}}(M_{\\star} \\,/\\, \\mathrm{M_{\\odot}})$')\n",
    "    ax.set_xlim(xlims); ax.set_ylim(ylims)\n",
    "    ax.legend()\n",
    "\n",
    "    ax = axd['lower right']\n",
    "    sns.kdeplot(y=gals_mass, ax=ax, color=color)\n",
    "    ax.set_ylim(ylims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d6a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp, wasserstein_distance\n",
    "\n",
    "# Number of posterior samples\n",
    "N_posterior = 1000\n",
    "\n",
    "# Get test set data (unscaled)\n",
    "halos_test_unscaled = halos_scalar.inverse_transform(halos_test)\n",
    "gals_test_unscaled = gals_scalar.inverse_transform(gals_test)\n",
    "\n",
    "# Storage for predictions\n",
    "n_test = len(halos_test)\n",
    "gals_pred_mean = np.zeros((n_test, 4))  # 4 galaxy properties\n",
    "gals_pred_random = np.zeros((n_test, 4))  # 4 galaxy properties\n",
    "\n",
    "# Generate posterior for each test galaxy\n",
    "print(\"Generating posteriors for test set...\")\n",
    "for i in range(n_test):\n",
    "    # Get the halo properties for this test sample\n",
    "    halo_i = torch.tensor(halos_test[i:i+1], dtype=torch.float32)\n",
    "    \n",
    "    # Generate N_posterior samples conditioned on this halo\n",
    "    with torch.no_grad():\n",
    "        gals_posterior_i = dist_x2_given_x1.condition(halo_i).sample(torch.Size([N_posterior]))\n",
    "    \n",
    "    # Inverse transform\n",
    "    gals_posterior_unscaled = gals_scalar.inverse_transform(gals_posterior_i.detach().cpu().numpy())\n",
    "    \n",
    "    # Mean prediction\n",
    "    gals_pred_mean[i] = gals_posterior_unscaled.mean(axis=0)\n",
    "    \n",
    "    # Random prediction\n",
    "    random_idx = np.random.randint(0, N_posterior)\n",
    "    gals_pred_random[i] = gals_posterior_unscaled[random_idx]\n",
    "\n",
    "# Property names\n",
    "property_names = ['Stellar Mass', 'SFR', 'Radius', 'Colour']\n",
    "\n",
    "# Compute metrics for both methods\n",
    "methods = {\n",
    "    'NF (Mean)': gals_pred_mean,\n",
    "    'NF (Random)': gals_pred_random\n",
    "}\n",
    "\n",
    "# Storage for metrics\n",
    "metrics_data = {\n",
    "    'PCC': {},\n",
    "    'RMSE': {},\n",
    "    'K-S Test': {},\n",
    "    'Wasserstein': {}\n",
    "}\n",
    "\n",
    "for method_name, predictions in methods.items():\n",
    "    pcc_vals = []\n",
    "    rmse_vals = []\n",
    "    ks_vals = []\n",
    "    ws_vals = []\n",
    "    \n",
    "    for j in range(4):\n",
    "        y_true = gals_test_unscaled[:, j]\n",
    "        y_pred = predictions[:, j]\n",
    "        \n",
    "        # PCC\n",
    "        pcc, _ = pearsonr(y_true, y_pred)\n",
    "        pcc_vals.append(pcc)\n",
    "        \n",
    "        # RMSE\n",
    "        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        rmse_vals.append(rmse)\n",
    "        \n",
    "        # K-S Test\n",
    "        ks_stat, _ = ks_2samp(y_true, y_pred)\n",
    "        ks_vals.append(ks_stat)\n",
    "        \n",
    "        # Wasserstein\n",
    "        ws_dist = wasserstein_distance(y_true, y_pred)\n",
    "        ws_vals.append(ws_dist)\n",
    "    \n",
    "    metrics_data['PCC'][method_name] = pcc_vals\n",
    "    metrics_data['RMSE'][method_name] = rmse_vals\n",
    "    metrics_data['K-S Test'][method_name] = ks_vals\n",
    "    metrics_data['Wasserstein'][method_name] = ws_vals\n",
    "\n",
    "# Create the comparison plots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metric_names = ['PCC', 'RMSE', 'K-S Test', 'Wasserstein']\n",
    "x = np.arange(len(property_names))\n",
    "width = 0.35\n",
    "\n",
    "for idx, metric_name in enumerate(metric_names):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    offset = 0\n",
    "    for i, (method_name, color) in enumerate(zip(['NF (Mean)', 'NF (Random)'], \n",
    "                                                   ['#1f77b4', '#ff7f0e'])):\n",
    "        values = metrics_data[metric_name][method_name]\n",
    "        ax.bar(x + offset, values, width, label=method_name, color=color, alpha=0.8)\n",
    "        offset += width\n",
    "    \n",
    "    ax.set_xlabel('Property', fontsize=12)\n",
    "    ax.set_ylabel(metric_name, fontsize=12)\n",
    "    ax.set_title(f'{metric_name}: Normalizing Flow Methods', fontsize=13, fontweight='bold')\n",
    "    ax.set_xticks(x + width / 2)\n",
    "    ax.set_xticklabels(property_names, rotation=0)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Also create line plots like in the reference image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Pearson Correlation plot\n",
    "ax = axes[0]\n",
    "for method_name, marker, color in zip(['NF (Mean)', 'NF (Random)'], \n",
    "                                       ['o-', 's-'], \n",
    "                                       ['#1f77b4', '#ff7f0e']):\n",
    "    ax.plot(property_names, metrics_data['PCC'][method_name], \n",
    "            marker, label=method_name, linewidth=2, markersize=8, color=color)\n",
    "\n",
    "ax.set_xlabel('Property', fontsize=12)\n",
    "ax.set_ylabel('Pearson Correlation', fontsize=12)\n",
    "ax.set_title('Pearson Correlation: Normalizing Flow Predictions', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "# RMSE plot\n",
    "ax = axes[1]\n",
    "for method_name, marker, color in zip(['NF (Mean)', 'NF (Random)'], \n",
    "                                       ['o-', 's-'], \n",
    "                                       ['#1f77b4', '#ff7f0e']):\n",
    "    ax.plot(property_names, metrics_data['RMSE'][method_name], \n",
    "            marker, label=method_name, linewidth=2, markersize=8, color=color)\n",
    "\n",
    "ax.set_xlabel('Property', fontsize=12)\n",
    "ax.set_ylabel('RMSE', fontsize=12)\n",
    "ax.set_title('RMSE: Normalizing Flow Predictions', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarp\n",
    "\n",
    "# Generate posterior samples for all test galaxies\n",
    "n_test = len(halos_test)\n",
    "N_posterior = 1000\n",
    "n_properties = 4\n",
    "\n",
    "# Storage for posterior samples: shape (N_posterior, n_test, n_properties)\n",
    "posterior_samples = np.zeros((N_posterior, n_test, n_properties))\n",
    "\n",
    "print(\"Generating posterior samples for TARP test...\")\n",
    "for i in range(n_test):\n",
    "    # Get the halo properties for this test sample\n",
    "    halo_i = torch.tensor(halos_test[i:i+1], dtype=torch.float32)\n",
    "    \n",
    "    # Generate N_posterior samples conditioned on this halo\n",
    "    with torch.no_grad():\n",
    "        gals_posterior_i = dist_x2_given_x1.condition(halo_i).sample(torch.Size([N_posterior]))\n",
    "    \n",
    "    # Inverse transform to original space\n",
    "    gals_posterior_unscaled = gals_scalar.inverse_transform(gals_posterior_i.detach().cpu().numpy())\n",
    "    posterior_samples[:, i, :] = gals_posterior_unscaled\n",
    "\n",
    "# True values (theta) - shape: (n_test, n_properties)\n",
    "theta_true = gals_test_unscaled\n",
    "\n",
    "# Property names\n",
    "property_names = ['SM', 'SFR', 'Colour', 'SR']\n",
    "\n",
    "print(\"\\n=== Step 5: TARP Test Results ===\\n\")\n",
    "\n",
    "# Perform TARP test for each property individually\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for j, prop_name in enumerate(property_names):\n",
    "    # Get samples for this property: shape (N_posterior, n_test, 1)\n",
    "    samples_j = posterior_samples[:, :, j:j+1]\n",
    "    theta_j = theta_true[:, j:j+1]\n",
    "    \n",
    "    # Get TARP coverage\n",
    "    ecp, alpha = tarp.get_tarp_coverage(\n",
    "        samples_j, \n",
    "        theta_j, \n",
    "        references='random',\n",
    "        metric='euclidean',\n",
    "        norm=True\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[j]\n",
    "    ax.plot([0, 1], [0, 1], 'k--', label='Ideal calibration')\n",
    "    ax.plot(alpha, ecp, 'b-', linewidth=2, label='TARP coverage')\n",
    "    ax.fill_between(alpha, alpha - np.sqrt(alpha * (1 - alpha) / n_test), \n",
    "                     alpha + np.sqrt(alpha * (1 - alpha) / n_test), \n",
    "                     alpha=0.2, color='gray', label='Expected deviation')\n",
    "    ax.set_xlabel('Credibility Level (α)')\n",
    "    ax.set_ylabel('Expected Coverage Probability')\n",
    "    ax.set_title(f'{prop_name}')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Test all properties together\n",
    "print(\"\\nTARP test for all galaxy properties combined:\")\n",
    "ecp_all, alpha_all = tarp.get_tarp_coverage(\n",
    "    posterior_samples, \n",
    "    theta_true, \n",
    "    references='random',\n",
    "    metric='euclidean',\n",
    "    norm=True\n",
    ")\n",
    "\n",
    "# Plot combined result\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Ideal calibration', linewidth=2)\n",
    "ax.plot(alpha_all, ecp_all, 'b-', linewidth=2, label='TARP coverage (all properties)')\n",
    "ax.fill_between(alpha_all, \n",
    "                 alpha_all - np.sqrt(alpha_all * (1 - alpha_all) / n_test), \n",
    "                 alpha_all + np.sqrt(alpha_all * (1 - alpha_all) / n_test), \n",
    "                 alpha=0.2, color='gray', label='Expected deviation')\n",
    "ax.set_xlabel('Credibility Level (α)', fontsize=12)\n",
    "ax.set_ylabel('Expected Coverage Probability', fontsize=12)\n",
    "ax.set_title('TARP Test: All Galaxy Properties', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
